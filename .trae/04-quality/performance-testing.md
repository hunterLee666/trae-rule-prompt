---
name: Performance Testing Patterns
description: 性能测试模式 - 负载测试、压力测试、基准测试、性能监控
version: "9.6"
priority: 85
alwaysApply: true
---

# 性能测试模式

> **"性能可测，优化有据。"**

## 一、测试类型

### 1.1 负载测试 (Load Testing)

```yaml
定义: 在预期负载下测试系统性能
目标: 验证系统在正常负载下的表现
指标:
  - 响应时间
  - 吞吐量
  - 资源使用率
  - 错误率

执行方式:
  工具: k6, Locust, JMeter, Gatling
  持续时间: 10-30分钟
  并发用户: 预期峰值的80%-100%
```

### 1.2 压力测试 (Stress Testing)

```yaml
定义: 在超负载条件下测试系统极限
目标: 发现系统的瓶颈和崩溃点
指标:
  - 最大并发数
  - 崩溃阈值
  - 恢复时间
  - 降级行为

执行方式:
  工具: k6, Locust, JMeter
  持续时间: 5-15分钟
  并发用户: 预期峰值的150%-200%
```

### 1.3 基准测试 (Benchmark Testing)

```yaml
定义: 测量特定操作的基准性能
目标: 建立性能基线，检测性能退化
指标:
  - 单次操作耗时
  - 内存分配
  - CPU周期
  - I/O操作

执行方式:
  工具: pytest-benchmark, JMH, Criterion
  迭代次数: 100-10000次
  预热次数: 10-100次
```

### 1.4 耐久性测试 (Endurance Testing)

```yaml
定义: 长时间运行测试系统稳定性
目标: 发现内存泄漏、资源耗尽等问题
指标:
  - 内存增长趋势
  - 连接池状态
  - 日志文件大小
  - 系统稳定性

执行方式:
  工具: 自定义脚本, 监控工具
  持续时间: 数小时到数天
  负载: 正常负载的50%-80%
```

---

## 二、性能指标

### 2.1 响应时间指标

| 指标 | 计算方式 | 优秀 | 良好 | 需优化 |
|-----|---------|------|------|--------|
| 平均响应时间 | ΣRT/n | <100ms | <300ms | <1000ms |
| P50响应时间 | 第50百分位 | <80ms | <200ms | <500ms |
| P90响应时间 | 第90百分位 | <200ms | <500ms | <1000ms |
| P99响应时间 | 第99百分位 | <500ms | <1000ms | <2000ms |
| 最大响应时间 | max(RT) | <1s | <3s | <10s |

### 2.2 吞吐量指标

| 指标 | 单位 | 优秀 | 良好 | 需优化 |
|-----|------|------|------|--------|
| 请求/秒 | RPS | >1000 | >500 | >100 |
| 事务/秒 | TPS | >500 | >200 | >50 |
| 数据传输率 | MB/s | >100 | >50 | >10 |

### 2.3 资源使用指标

| 资源 | 优秀 | 良好 | 需优化 |
|-----|------|------|--------|
| CPU使用率 | <50% | <70% | <90% |
| 内存使用率 | <60% | <75% | <90% |
| 磁盘I/O | <50% | <70% | <90% |
| 网络带宽 | <30% | <50% | <80% |

### 2.4 错误率指标

| 错误类型 | 优秀 | 良好 | 需优化 |
|---------|------|------|--------|
| HTTP错误率 | <0.1% | <1% | <5% |
| 超时率 | <0.5% | <2% | <10% |
| 断路器触发 | 0次 | <5次 | <20次 |

---

## 三、测试场景

### 3.1 API性能测试

```yaml
场景: REST API性能测试
工具: k6, Locust

测试脚本示例 (k6):
  import http from 'k6/http';
  import { check, sleep } from 'k6';
  
  export let options = {
    stages: [
      { duration: '2m', target: 100 },  // 爬升
      { duration: '5m', target: 100 },  // 稳定
      { duration: '2m', target: 200 },  // 压力
      { duration: '2m', target: 0 },    // 下降
    ],
    thresholds: {
      http_req_duration: ['p(99)<500'],
      http_req_failed: ['rate<0.01'],
    },
  };
  
  export default function() {
    let res = http.get('https://api.example.com/users');
    check(res, { 'status is 200': (r) => r.status == 200 });
    sleep(1);
  }

验收标准:
  - P99响应时间 < 500ms
  - 错误率 < 1%
  - 吞吐量 > 100 RPS
```

### 3.2 数据库性能测试

```yaml
场景: 数据库查询性能测试
工具: pgbench, sysbench, JMeter

测试类型:
  - 读性能测试
  - 写性能测试
  - 混合读写测试
  - 连接池测试

关键指标:
  - 查询延迟
  - 事务吞吐量
  - 连接等待时间
  - 锁等待时间

验收标准:
  - 简单查询 < 10ms
  - 复杂查询 < 100ms
  - 写入延迟 < 50ms
```

### 3.3 前端性能测试

```yaml
场景: 前端页面加载性能
工具: Lighthouse, WebPageTest, Puppeteer

测试指标:
  Core Web Vitals:
    - LCP (Largest Contentful Paint): < 2.5s
    - FID (First Input Delay): < 100ms
    - CLS (Cumulative Layout Shift): < 0.1
    
  其他指标:
    - FCP (First Contentful Paint): < 1.8s
    - TTI (Time to Interactive): < 3.8s
    - TBT (Total Blocking Time): < 200ms

验收标准:
  - Lighthouse性能分数 > 90
  - 所有Core Web Vitals通过
```

### 3.4 微服务性能测试

```yaml
场景: 微服务链路性能测试
工具: k6 + 服务网格

测试类型:
  - 服务间调用延迟
  - 服务发现性能
  - 负载均衡效果
  - 熔断降级行为

关键指标:
  - 链路总延迟
  - 各服务延迟分布
  - 重试次数
  - 降级触发次数

验收标准:
  - 单服务延迟 < 50ms
  - 链路总延迟 < 500ms
  - 重试成功率 > 95%
```

---

## 四、测试工具选择

### 4.1 工具对比

| 工具 | 类型 | 适用场景 | 优点 | 缺点 |
|-----|------|---------|------|------|
| k6 | 负载测试 | API, 微服务 | 脚本简单, 云原生 | 需要编码 |
| Locust | 负载测试 | Web, API | Python友好, 分布式 | UI较简单 |
| JMeter | 综合 | 企业应用 | 功能全面, 插件多 | 内存占用大 |
| Gatling | 负载测试 | 高并发 | 性能高, Scala DSL | 学习曲线 |
| pytest-benchmark | 基准测试 | Python代码 | 集成简单 | 仅限Python |
| Lighthouse | 前端 | Web页面 | Google官方 | 仅浏览器 |

### 4.2 工具选择指南

```yaml
API负载测试:
  首选: k6
  备选: Locust, Gatling
  
前端性能测试:
  首选: Lighthouse
  备选: WebPageTest
  
数据库性能测试:
  PostgreSQL: pgbench
  MySQL: sysbench
  通用: JMeter
  
代码基准测试:
  Python: pytest-benchmark
  Java: JMH
  Rust: Criterion
  Go: go test -bench
```

---

## 五、测试流程

### 5.1 测试准备

```yaml
环境准备:
  - 独立的性能测试环境
  - 与生产环境相似的配置
  - 足够的测试数据
  - 监控工具部署

数据准备:
  - 生成测试数据
  - 数据量与生产相当
  - 数据分布合理
  - 敏感数据脱敏

基线建立:
  - 记录当前性能基线
  - 确定性能目标
  - 定义验收标准
```

### 5.2 测试执行

```yaml
执行步骤:
  1. 预热系统
     - 运行轻量负载
     - 预热缓存
     - 建立连接池
     
  2. 执行测试
     - 按计划执行测试场景
     - 收集性能指标
     - 记录异常情况
     
  3. 监控系统
     - 监控资源使用
     - 监控错误日志
     - 监控业务指标
     
  4. 收集结果
     - 导出测试报告
     - 保存原始数据
     - 记录测试环境
```

### 5.3 结果分析

```yaml
分析维度:
  性能指标分析:
    - 对比基线数据
    - 识别性能瓶颈
    - 分析异常点
    
  资源分析:
    - CPU使用分析
    - 内存使用分析
    - I/O分析
    
  错误分析:
    - 错误类型分布
    - 错误发生时机
    - 错误影响范围

报告输出:
  - 测试摘要
  - 性能趋势图
  - 瓶颈分析
  - 优化建议
```

---

## 六、性能优化建议

### 6.1 常见瓶颈

```yaml
CPU瓶颈:
  症状: CPU使用率高, 响应慢
  原因: 复杂计算, 低效算法
  解决: 算法优化, 并行处理

内存瓶颈:
  症状: 内存使用高, GC频繁
  原因: 内存泄漏, 大对象
  解决: 内存分析, 对象池

I/O瓶颈:
  症状: 磁盘/网络等待高
  原因: 大量小IO, 同步IO
  解决: 批量处理, 异步IO

数据库瓶颈:
  症状: 查询慢, 连接等待
  原因: 缺少索引, 慢查询
  解决: 索引优化, 查询优化
```

### 6.2 优化策略

```yaml
代码优化:
  - 算法复杂度优化
  - 减少不必要的计算
  - 使用缓存
  - 异步处理

架构优化:
  - 水平扩展
  - 读写分离
  - 分库分表
  - CDN加速

配置优化:
  - 连接池大小
  - 线程池大小
  - 缓存配置
  - 超时设置
```

---

## 七、CI/CD集成

### 7.1 性能测试流水线

```yaml
stages:
  - build
  - test
  - performance-test
  - deploy

performance-test:
  stage: performance-test
  script:
    - k6 run tests/performance/load-test.js
  artifacts:
    reports:
      performance: performance-report.json
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == "main"
```

### 7.2 性能门禁

```yaml
性能门禁规则:
  - P99响应时间不超过基线的120%
  - 错误率不超过1%
  - 吞吐量不低于基线的80%
  - 无新增性能瓶颈

门禁失败处理:
  - 阻止合并
  - 发送通知
  - 记录性能退化
```

---

## 八、AI Agent性能基准

### 8.1 Agent响应时间基准

```yaml
简单任务 (L1):
  意图理解: < 1秒
  工具调用: < 3秒
  结果生成: < 2秒
  总响应: < 5秒

中等任务 (L2):
  意图理解: < 2秒
  任务规划: < 3秒
  工具调用: < 10秒
  结果生成: < 3秒
  总响应: < 15秒

复杂任务 (L3):
  意图理解: < 3秒
  任务规划: < 5秒
  工具调用: < 30秒
  结果生成: < 5秒
  总响应: < 45秒

超复杂任务 (L4):
  意图理解: < 5秒
  任务规划: < 10秒
  工具调用: < 60秒
  结果生成: < 10秒
  总响应: < 90秒
```

### 8.2 工具调用性能基准

```yaml
文件操作:
  Read (小文件 < 1MB): < 100ms
  Read (大文件 > 10MB): < 1秒
  Write (小文件): < 200ms
  Grep (小项目): < 500ms
  Grep (大项目): < 3秒

搜索操作:
  SearchCodebase: < 2秒
  Glob: < 500ms
  LS: < 200ms

网络操作:
  WebFetch: < 5秒
  WebSearch: < 10秒

命令执行:
  短命令: < 5秒
  长命令: < 30秒
```

### 8.3 资源使用基准

```yaml
内存使用:
  基础运行: < 500MB
  大文件处理: < 2GB
  多Agent协作: < 4GB

CPU使用:
  空闲: < 5%
  单任务: < 50%
  多任务: < 80%

网络带宽:
  LLM调用: < 1MB/请求
  文件传输: < 10MB/秒
```

### 8.4 性能监控指标

```yaml
实时监控:
  - 响应时间分布
  - 工具调用频率
  - 错误率趋势
  - 资源使用率

告警阈值:
  响应时间 > 基准150%: 警告
  响应时间 > 基准200%: 严重
  错误率 > 5%: 警告
  错误率 > 10%: 严重
  内存使用 > 80%: 警告
  内存使用 > 90%: 严重

监控工具:
  - Prometheus + Grafana
  - 自定义日志分析
  - APM工具集成
```
